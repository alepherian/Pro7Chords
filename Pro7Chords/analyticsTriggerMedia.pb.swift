// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: analyticsTriggerMedia.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

struct Analytics_TriggerMediaInformation: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var sourceType: Analytics_TriggerMediaInformation.SourceType = .local

  var mediaType: Analytics_TriggerMediaInformation.OneOf_MediaType? = nil

  var video: Analytics_TriggerMediaInformation.Video {
    get {
      if case .video(let v)? = mediaType {return v}
      return Analytics_TriggerMediaInformation.Video()
    }
    set {mediaType = .video(newValue)}
  }

  var image: Analytics_TriggerMediaInformation.Image {
    get {
      if case .image(let v)? = mediaType {return v}
      return Analytics_TriggerMediaInformation.Image()
    }
    set {mediaType = .image(newValue)}
  }

  var audio: Analytics_TriggerMediaInformation.Audio {
    get {
      if case .audio(let v)? = mediaType {return v}
      return Analytics_TriggerMediaInformation.Audio()
    }
    set {mediaType = .audio(newValue)}
  }

  var liveVideo: Analytics_TriggerMediaInformation.LiveVideo {
    get {
      if case .liveVideo(let v)? = mediaType {return v}
      return Analytics_TriggerMediaInformation.LiveVideo()
    }
    set {mediaType = .liveVideo(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_MediaType: Equatable, Sendable {
    case video(Analytics_TriggerMediaInformation.Video)
    case image(Analytics_TriggerMediaInformation.Image)
    case audio(Analytics_TriggerMediaInformation.Audio)
    case liveVideo(Analytics_TriggerMediaInformation.LiveVideo)

  }

  enum CompletionTarget: SwiftProtobuf.Enum, Swift.CaseIterable {
    typealias RawValue = Int
    case none // = 0
    case next // = 1
    case random // = 2
    case cue // = 3
    case first // = 4
    case UNRECOGNIZED(Int)

    init() {
      self = .none
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .none
      case 1: self = .next
      case 2: self = .random
      case 3: self = .cue
      case 4: self = .first
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .none: return 0
      case .next: return 1
      case .random: return 2
      case .cue: return 3
      case .first: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    static let allCases: [Analytics_TriggerMediaInformation.CompletionTarget] = [
      .none,
      .next,
      .random,
      .cue,
      .first,
    ]

  }

  enum SourceType: SwiftProtobuf.Enum, Swift.CaseIterable {
    typealias RawValue = Int
    case local // = 0
    case procontent // = 1
    case UNRECOGNIZED(Int)

    init() {
      self = .local
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .local
      case 1: self = .procontent
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .local: return 0
      case .procontent: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    static let allCases: [Analytics_TriggerMediaInformation.SourceType] = [
      .local,
      .procontent,
    ]

  }

  struct Transition: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var isDefault: Bool = false

    var name: String = String()

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct VisualMedia: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var behavior: Analytics_TriggerMediaInformation.VisualMedia.Behavior = .background

    var scaleMode: Analytics_TriggerMediaInformation.VisualMedia.ScaleMode = .fit

    var flipMode: Analytics_TriggerMediaInformation.VisualMedia.FlipMode = .none

    var nativeRotation: Analytics_TriggerMediaInformation.VisualMedia.NativeRotation = .standard

    var resolution: Analytics_TriggerMediaInformation.VisualMedia.Size {
      get {return _resolution ?? Analytics_TriggerMediaInformation.VisualMedia.Size()}
      set {_resolution = newValue}
    }
    /// Returns true if `resolution` has been explicitly set.
    var hasResolution: Bool {return self._resolution != nil}
    /// Clears the value of `resolution`. Subsequent reads from it will return its default value.
    mutating func clearResolution() {self._resolution = nil}

    var enabledEffectsCount: UInt32 = 0

    var hasEffectPreset_p: Bool = false

    var transition: Analytics_TriggerMediaInformation.Transition {
      get {return _transition ?? Analytics_TriggerMediaInformation.Transition()}
      set {_transition = newValue}
    }
    /// Returns true if `transition` has been explicitly set.
    var hasTransition: Bool {return self._transition != nil}
    /// Clears the value of `transition`. Subsequent reads from it will return its default value.
    mutating func clearTransition() {self._transition = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum Behavior: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case background // = 0
      case foreground // = 1
      case videoInput // = 2
      case UNRECOGNIZED(Int)

      init() {
        self = .background
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .background
        case 1: self = .foreground
        case 2: self = .videoInput
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .background: return 0
        case .foreground: return 1
        case .videoInput: return 2
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.VisualMedia.Behavior] = [
        .background,
        .foreground,
        .videoInput,
      ]

    }

    enum ScaleMode: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case fit // = 0
      case fill // = 1
      case stretch // = 2
      case blur // = 3
      case UNRECOGNIZED(Int)

      init() {
        self = .fit
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .fit
        case 1: self = .fill
        case 2: self = .stretch
        case 3: self = .blur
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .fit: return 0
        case .fill: return 1
        case .stretch: return 2
        case .blur: return 3
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.VisualMedia.ScaleMode] = [
        .fit,
        .fill,
        .stretch,
        .blur,
      ]

    }

    enum FlipMode: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case none // = 0
      case horizontal // = 1
      case vertical // = 2
      case both // = 3
      case UNRECOGNIZED(Int)

      init() {
        self = .none
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .none
        case 1: self = .horizontal
        case 2: self = .vertical
        case 3: self = .both
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .none: return 0
        case .horizontal: return 1
        case .vertical: return 2
        case .both: return 3
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.VisualMedia.FlipMode] = [
        .none,
        .horizontal,
        .vertical,
        .both,
      ]

    }

    enum NativeRotation: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case standard // = 0
      case nativeRotation90 // = 90
      case nativeRotation180 // = 180
      case nativeRotation270 // = 270
      case UNRECOGNIZED(Int)

      init() {
        self = .standard
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .standard
        case 90: self = .nativeRotation90
        case 180: self = .nativeRotation180
        case 270: self = .nativeRotation270
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .standard: return 0
        case .nativeRotation90: return 90
        case .nativeRotation180: return 180
        case .nativeRotation270: return 270
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.VisualMedia.NativeRotation] = [
        .standard,
        .nativeRotation90,
        .nativeRotation180,
        .nativeRotation270,
      ]

    }

    struct Size: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var width: UInt32 = 0

      var height: UInt32 = 0

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}
    }

    init() {}

    fileprivate var _resolution: Analytics_TriggerMediaInformation.VisualMedia.Size? = nil
    fileprivate var _transition: Analytics_TriggerMediaInformation.Transition? = nil
  }

  struct Transport: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var sourceDurationRange: Analytics_TriggerMediaInformation.Transport.DurationRange = .durationUnder10S

    var hasAudioRampIn_p: Bool = false

    var hasAudioRampOut_p: Bool = false

    var hasInPoint_p: Bool = false

    var hasOutPoint_p: Bool = false

    var playRate: Double = 0

    var playbackMarkerCount: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum DurationRange: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case durationUnder10S // = 0
      case duration10STo30S // = 1
      case duration30STo60S // = 2
      case duration1MTo5M // = 3
      case duration5MTo10M // = 4
      case duration10MTo30M // = 5
      case duration30MTo60M // = 6
      case duration1HTo2H // = 7
      case durationOver2H // = 8
      case UNRECOGNIZED(Int)

      init() {
        self = .durationUnder10S
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .durationUnder10S
        case 1: self = .duration10STo30S
        case 2: self = .duration30STo60S
        case 3: self = .duration1MTo5M
        case 4: self = .duration5MTo10M
        case 5: self = .duration10MTo30M
        case 6: self = .duration30MTo60M
        case 7: self = .duration1HTo2H
        case 8: self = .durationOver2H
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .durationUnder10S: return 0
        case .duration10STo30S: return 1
        case .duration30STo60S: return 2
        case .duration1MTo5M: return 3
        case .duration5MTo10M: return 4
        case .duration10MTo30M: return 5
        case .duration30MTo60M: return 6
        case .duration1HTo2H: return 7
        case .durationOver2H: return 8
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.Transport.DurationRange] = [
        .durationUnder10S,
        .duration10STo30S,
        .duration30STo60S,
        .duration1MTo5M,
        .duration5MTo10M,
        .duration10MTo30M,
        .duration30MTo60M,
        .duration1HTo2H,
        .durationOver2H,
      ]

    }

    init() {}
  }

  struct Video: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var visualMedia: Analytics_TriggerMediaInformation.VisualMedia {
      get {return _storage._visualMedia ?? Analytics_TriggerMediaInformation.VisualMedia()}
      set {_uniqueStorage()._visualMedia = newValue}
    }
    /// Returns true if `visualMedia` has been explicitly set.
    var hasVisualMedia: Bool {return _storage._visualMedia != nil}
    /// Clears the value of `visualMedia`. Subsequent reads from it will return its default value.
    mutating func clearVisualMedia() {_uniqueStorage()._visualMedia = nil}

    var playbackBehavior: Analytics_TriggerMediaInformation.Video.PlaybackBehavior {
      get {return _storage._playbackBehavior}
      set {_uniqueStorage()._playbackBehavior = newValue}
    }

    var completionTarget: Analytics_TriggerMediaInformation.CompletionTarget {
      get {return _storage._completionTarget}
      set {_uniqueStorage()._completionTarget = newValue}
    }

    var softLoopEnabled: Bool {
      get {return _storage._softLoopEnabled}
      set {_uniqueStorage()._softLoopEnabled = newValue}
    }

    var softLoopDuration: Double {
      get {return _storage._softLoopDuration}
      set {_uniqueStorage()._softLoopDuration = newValue}
    }

    var frameRate: Double {
      get {return _storage._frameRate}
      set {_uniqueStorage()._frameRate = newValue}
    }

    var audioChannelCount: UInt32 {
      get {return _storage._audioChannelCount}
      set {_uniqueStorage()._audioChannelCount = newValue}
    }

    var transport: Analytics_TriggerMediaInformation.Transport {
      get {return _storage._transport ?? Analytics_TriggerMediaInformation.Transport()}
      set {_uniqueStorage()._transport = newValue}
    }
    /// Returns true if `transport` has been explicitly set.
    var hasTransport: Bool {return _storage._transport != nil}
    /// Clears the value of `transport`. Subsequent reads from it will return its default value.
    mutating func clearTransport() {_uniqueStorage()._transport = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum PlaybackBehavior: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case stop // = 0
      case loop // = 1
      case loopForPlayCount // = 2
      case loopForTime // = 3
      case UNRECOGNIZED(Int)

      init() {
        self = .stop
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .stop
        case 1: self = .loop
        case 2: self = .loopForPlayCount
        case 3: self = .loopForTime
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .stop: return 0
        case .loop: return 1
        case .loopForPlayCount: return 2
        case .loopForTime: return 3
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.Video.PlaybackBehavior] = [
        .stop,
        .loop,
        .loopForPlayCount,
        .loopForTime,
      ]

    }

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Audio: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var behavior: Analytics_TriggerMediaInformation.Audio.Behavior = .tune

    var playbackBehavior: Analytics_TriggerMediaInformation.Audio.PlaybackBehavior = .stop

    var transition: Analytics_TriggerMediaInformation.Transition {
      get {return _transition ?? Analytics_TriggerMediaInformation.Transition()}
      set {_transition = newValue}
    }
    /// Returns true if `transition` has been explicitly set.
    var hasTransition: Bool {return self._transition != nil}
    /// Clears the value of `transition`. Subsequent reads from it will return its default value.
    mutating func clearTransition() {self._transition = nil}

    var audioChannelCount: UInt32 = 0

    var transport: Analytics_TriggerMediaInformation.Transport {
      get {return _transport ?? Analytics_TriggerMediaInformation.Transport()}
      set {_transport = newValue}
    }
    /// Returns true if `transport` has been explicitly set.
    var hasTransport: Bool {return self._transport != nil}
    /// Clears the value of `transport`. Subsequent reads from it will return its default value.
    mutating func clearTransport() {self._transport = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum Behavior: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case tune // = 0
      case sound // = 1
      case UNRECOGNIZED(Int)

      init() {
        self = .tune
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .tune
        case 1: self = .sound
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .tune: return 0
        case .sound: return 1
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.Audio.Behavior] = [
        .tune,
        .sound,
      ]

    }

    enum PlaybackBehavior: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case stop // = 0
      case loop // = 1
      case next // = 2
      case UNRECOGNIZED(Int)

      init() {
        self = .stop
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .stop
        case 1: self = .loop
        case 2: self = .next
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .stop: return 0
        case .loop: return 1
        case .next: return 2
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Analytics_TriggerMediaInformation.Audio.PlaybackBehavior] = [
        .stop,
        .loop,
        .next,
      ]

    }

    init() {}

    fileprivate var _transition: Analytics_TriggerMediaInformation.Transition? = nil
    fileprivate var _transport: Analytics_TriggerMediaInformation.Transport? = nil
  }

  struct Image: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var visualMedia: Analytics_TriggerMediaInformation.VisualMedia {
      get {return _visualMedia ?? Analytics_TriggerMediaInformation.VisualMedia()}
      set {_visualMedia = newValue}
    }
    /// Returns true if `visualMedia` has been explicitly set.
    var hasVisualMedia: Bool {return self._visualMedia != nil}
    /// Clears the value of `visualMedia`. Subsequent reads from it will return its default value.
    mutating func clearVisualMedia() {self._visualMedia = nil}

    var transition: Analytics_TriggerMediaInformation.Transition {
      get {return _transition ?? Analytics_TriggerMediaInformation.Transition()}
      set {_transition = newValue}
    }
    /// Returns true if `transition` has been explicitly set.
    var hasTransition: Bool {return self._transition != nil}
    /// Clears the value of `transition`. Subsequent reads from it will return its default value.
    mutating func clearTransition() {self._transition = nil}

    var completionTarget: Analytics_TriggerMediaInformation.CompletionTarget = .none

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _visualMedia: Analytics_TriggerMediaInformation.VisualMedia? = nil
    fileprivate var _transition: Analytics_TriggerMediaInformation.Transition? = nil
  }

  struct LiveVideo: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var visualMedia: Analytics_TriggerMediaInformation.VisualMedia {
      get {return _visualMedia ?? Analytics_TriggerMediaInformation.VisualMedia()}
      set {_visualMedia = newValue}
    }
    /// Returns true if `visualMedia` has been explicitly set.
    var hasVisualMedia: Bool {return self._visualMedia != nil}
    /// Clears the value of `visualMedia`. Subsequent reads from it will return its default value.
    mutating func clearVisualMedia() {self._visualMedia = nil}

    var frameRate: Double = 0

    var audioChannelCount: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _visualMedia: Analytics_TriggerMediaInformation.VisualMedia? = nil
  }

  init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "rv.analytics"

extension Analytics_TriggerMediaInformation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".TriggerMediaInformation"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "source_type"),
    2: .same(proto: "video"),
    3: .same(proto: "image"),
    4: .same(proto: "audio"),
    5: .standard(proto: "live_video"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.sourceType) }()
      case 2: try {
        var v: Analytics_TriggerMediaInformation.Video?
        var hadOneofValue = false
        if let current = self.mediaType {
          hadOneofValue = true
          if case .video(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.mediaType = .video(v)
        }
      }()
      case 3: try {
        var v: Analytics_TriggerMediaInformation.Image?
        var hadOneofValue = false
        if let current = self.mediaType {
          hadOneofValue = true
          if case .image(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.mediaType = .image(v)
        }
      }()
      case 4: try {
        var v: Analytics_TriggerMediaInformation.Audio?
        var hadOneofValue = false
        if let current = self.mediaType {
          hadOneofValue = true
          if case .audio(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.mediaType = .audio(v)
        }
      }()
      case 5: try {
        var v: Analytics_TriggerMediaInformation.LiveVideo?
        var hadOneofValue = false
        if let current = self.mediaType {
          hadOneofValue = true
          if case .liveVideo(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.mediaType = .liveVideo(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.sourceType != .local {
      try visitor.visitSingularEnumField(value: self.sourceType, fieldNumber: 1)
    }
    switch self.mediaType {
    case .video?: try {
      guard case .video(let v)? = self.mediaType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .image?: try {
      guard case .image(let v)? = self.mediaType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .audio?: try {
      guard case .audio(let v)? = self.mediaType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .liveVideo?: try {
      guard case .liveVideo(let v)? = self.mediaType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation, rhs: Analytics_TriggerMediaInformation) -> Bool {
    if lhs.sourceType != rhs.sourceType {return false}
    if lhs.mediaType != rhs.mediaType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.CompletionTarget: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "COMPLETION_TARGET_NONE"),
    1: .same(proto: "COMPLETION_TARGET_NEXT"),
    2: .same(proto: "COMPLETION_TARGET_RANDOM"),
    3: .same(proto: "COMPLETION_TARGET_CUE"),
    4: .same(proto: "COMPLETION_TARGET_FIRST"),
  ]
}

extension Analytics_TriggerMediaInformation.SourceType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SOURCE_TYPE_LOCAL"),
    1: .same(proto: "SOURCE_TYPE_PROCONTENT"),
  ]
}

extension Analytics_TriggerMediaInformation.Transition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.protoMessageName + ".Transition"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "is_default"),
    2: .same(proto: "name"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.isDefault) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.isDefault != false {
      try visitor.visitSingularBoolField(value: self.isDefault, fieldNumber: 1)
    }
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.Transition, rhs: Analytics_TriggerMediaInformation.Transition) -> Bool {
    if lhs.isDefault != rhs.isDefault {return false}
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.VisualMedia: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.protoMessageName + ".VisualMedia"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "behavior"),
    2: .standard(proto: "scale_mode"),
    3: .standard(proto: "flip_mode"),
    4: .standard(proto: "native_rotation"),
    5: .same(proto: "resolution"),
    6: .standard(proto: "enabled_effects_count"),
    7: .standard(proto: "has_effect_preset"),
    8: .same(proto: "transition"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.behavior) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.scaleMode) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.flipMode) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.nativeRotation) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._resolution) }()
      case 6: try { try decoder.decodeSingularUInt32Field(value: &self.enabledEffectsCount) }()
      case 7: try { try decoder.decodeSingularBoolField(value: &self.hasEffectPreset_p) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._transition) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.behavior != .background {
      try visitor.visitSingularEnumField(value: self.behavior, fieldNumber: 1)
    }
    if self.scaleMode != .fit {
      try visitor.visitSingularEnumField(value: self.scaleMode, fieldNumber: 2)
    }
    if self.flipMode != .none {
      try visitor.visitSingularEnumField(value: self.flipMode, fieldNumber: 3)
    }
    if self.nativeRotation != .standard {
      try visitor.visitSingularEnumField(value: self.nativeRotation, fieldNumber: 4)
    }
    try { if let v = self._resolution {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if self.enabledEffectsCount != 0 {
      try visitor.visitSingularUInt32Field(value: self.enabledEffectsCount, fieldNumber: 6)
    }
    if self.hasEffectPreset_p != false {
      try visitor.visitSingularBoolField(value: self.hasEffectPreset_p, fieldNumber: 7)
    }
    try { if let v = self._transition {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.VisualMedia, rhs: Analytics_TriggerMediaInformation.VisualMedia) -> Bool {
    if lhs.behavior != rhs.behavior {return false}
    if lhs.scaleMode != rhs.scaleMode {return false}
    if lhs.flipMode != rhs.flipMode {return false}
    if lhs.nativeRotation != rhs.nativeRotation {return false}
    if lhs._resolution != rhs._resolution {return false}
    if lhs.enabledEffectsCount != rhs.enabledEffectsCount {return false}
    if lhs.hasEffectPreset_p != rhs.hasEffectPreset_p {return false}
    if lhs._transition != rhs._transition {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.VisualMedia.Behavior: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "BEHAVIOR_BACKGROUND"),
    1: .same(proto: "BEHAVIOR_FOREGROUND"),
    2: .same(proto: "BEHAVIOR_VIDEO_INPUT"),
  ]
}

extension Analytics_TriggerMediaInformation.VisualMedia.ScaleMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SCALE_MODE_FIT"),
    1: .same(proto: "SCALE_MODE_FILL"),
    2: .same(proto: "SCALE_MODE_STRETCH"),
    3: .same(proto: "SCALE_MODE_BLUR"),
  ]
}

extension Analytics_TriggerMediaInformation.VisualMedia.FlipMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "FLIP_MODE_NONE"),
    1: .same(proto: "FLIP_MODE_HORIZONTAL"),
    2: .same(proto: "FLIP_MODE_VERTICAL"),
    3: .same(proto: "FLIP_MODE_BOTH"),
  ]
}

extension Analytics_TriggerMediaInformation.VisualMedia.NativeRotation: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "NATIVE_ROTATION_STANDARD"),
    90: .same(proto: "NATIVE_ROTATION_90"),
    180: .same(proto: "NATIVE_ROTATION_180"),
    270: .same(proto: "NATIVE_ROTATION_270"),
  ]
}

extension Analytics_TriggerMediaInformation.VisualMedia.Size: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.VisualMedia.protoMessageName + ".Size"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "width"),
    2: .same(proto: "height"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.width) }()
      case 2: try { try decoder.decodeSingularUInt32Field(value: &self.height) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.width != 0 {
      try visitor.visitSingularUInt32Field(value: self.width, fieldNumber: 1)
    }
    if self.height != 0 {
      try visitor.visitSingularUInt32Field(value: self.height, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.VisualMedia.Size, rhs: Analytics_TriggerMediaInformation.VisualMedia.Size) -> Bool {
    if lhs.width != rhs.width {return false}
    if lhs.height != rhs.height {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.Transport: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.protoMessageName + ".Transport"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "source_duration_range"),
    2: .standard(proto: "has_audio_ramp_in"),
    3: .standard(proto: "has_audio_ramp_out"),
    4: .standard(proto: "has_in_point"),
    5: .standard(proto: "has_out_point"),
    6: .standard(proto: "play_rate"),
    7: .standard(proto: "playback_marker_count"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.sourceDurationRange) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.hasAudioRampIn_p) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.hasAudioRampOut_p) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.hasInPoint_p) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self.hasOutPoint_p) }()
      case 6: try { try decoder.decodeSingularDoubleField(value: &self.playRate) }()
      case 7: try { try decoder.decodeSingularUInt32Field(value: &self.playbackMarkerCount) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.sourceDurationRange != .durationUnder10S {
      try visitor.visitSingularEnumField(value: self.sourceDurationRange, fieldNumber: 1)
    }
    if self.hasAudioRampIn_p != false {
      try visitor.visitSingularBoolField(value: self.hasAudioRampIn_p, fieldNumber: 2)
    }
    if self.hasAudioRampOut_p != false {
      try visitor.visitSingularBoolField(value: self.hasAudioRampOut_p, fieldNumber: 3)
    }
    if self.hasInPoint_p != false {
      try visitor.visitSingularBoolField(value: self.hasInPoint_p, fieldNumber: 4)
    }
    if self.hasOutPoint_p != false {
      try visitor.visitSingularBoolField(value: self.hasOutPoint_p, fieldNumber: 5)
    }
    if self.playRate.bitPattern != 0 {
      try visitor.visitSingularDoubleField(value: self.playRate, fieldNumber: 6)
    }
    if self.playbackMarkerCount != 0 {
      try visitor.visitSingularUInt32Field(value: self.playbackMarkerCount, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.Transport, rhs: Analytics_TriggerMediaInformation.Transport) -> Bool {
    if lhs.sourceDurationRange != rhs.sourceDurationRange {return false}
    if lhs.hasAudioRampIn_p != rhs.hasAudioRampIn_p {return false}
    if lhs.hasAudioRampOut_p != rhs.hasAudioRampOut_p {return false}
    if lhs.hasInPoint_p != rhs.hasInPoint_p {return false}
    if lhs.hasOutPoint_p != rhs.hasOutPoint_p {return false}
    if lhs.playRate != rhs.playRate {return false}
    if lhs.playbackMarkerCount != rhs.playbackMarkerCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.Transport.DurationRange: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DURATION_UNDER_10S"),
    1: .same(proto: "DURATION_10S_TO_30S"),
    2: .same(proto: "DURATION_30S_TO_60S"),
    3: .same(proto: "DURATION_1M_TO_5M"),
    4: .same(proto: "DURATION_5M_TO_10M"),
    5: .same(proto: "DURATION_10M_TO_30M"),
    6: .same(proto: "DURATION_30M_TO_60M"),
    7: .same(proto: "DURATION_1H_TO_2H"),
    8: .same(proto: "DURATION_OVER_2H"),
  ]
}

extension Analytics_TriggerMediaInformation.Video: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.protoMessageName + ".Video"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    7: .standard(proto: "visual_media"),
    8: .standard(proto: "playback_behavior"),
    9: .standard(proto: "completion_target"),
    10: .standard(proto: "soft_loop_enabled"),
    11: .standard(proto: "soft_loop_duration"),
    12: .standard(proto: "frame_rate"),
    13: .standard(proto: "audio_channel_count"),
    14: .same(proto: "transport"),
  ]

  fileprivate class _StorageClass {
    var _visualMedia: Analytics_TriggerMediaInformation.VisualMedia? = nil
    var _playbackBehavior: Analytics_TriggerMediaInformation.Video.PlaybackBehavior = .stop
    var _completionTarget: Analytics_TriggerMediaInformation.CompletionTarget = .none
    var _softLoopEnabled: Bool = false
    var _softLoopDuration: Double = 0
    var _frameRate: Double = 0
    var _audioChannelCount: UInt32 = 0
    var _transport: Analytics_TriggerMediaInformation.Transport? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _visualMedia = source._visualMedia
      _playbackBehavior = source._playbackBehavior
      _completionTarget = source._completionTarget
      _softLoopEnabled = source._softLoopEnabled
      _softLoopDuration = source._softLoopDuration
      _frameRate = source._frameRate
      _audioChannelCount = source._audioChannelCount
      _transport = source._transport
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._visualMedia) }()
        case 8: try { try decoder.decodeSingularEnumField(value: &_storage._playbackBehavior) }()
        case 9: try { try decoder.decodeSingularEnumField(value: &_storage._completionTarget) }()
        case 10: try { try decoder.decodeSingularBoolField(value: &_storage._softLoopEnabled) }()
        case 11: try { try decoder.decodeSingularDoubleField(value: &_storage._softLoopDuration) }()
        case 12: try { try decoder.decodeSingularDoubleField(value: &_storage._frameRate) }()
        case 13: try { try decoder.decodeSingularUInt32Field(value: &_storage._audioChannelCount) }()
        case 14: try { try decoder.decodeSingularMessageField(value: &_storage._transport) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._visualMedia {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      if _storage._playbackBehavior != .stop {
        try visitor.visitSingularEnumField(value: _storage._playbackBehavior, fieldNumber: 8)
      }
      if _storage._completionTarget != .none {
        try visitor.visitSingularEnumField(value: _storage._completionTarget, fieldNumber: 9)
      }
      if _storage._softLoopEnabled != false {
        try visitor.visitSingularBoolField(value: _storage._softLoopEnabled, fieldNumber: 10)
      }
      if _storage._softLoopDuration.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._softLoopDuration, fieldNumber: 11)
      }
      if _storage._frameRate.bitPattern != 0 {
        try visitor.visitSingularDoubleField(value: _storage._frameRate, fieldNumber: 12)
      }
      if _storage._audioChannelCount != 0 {
        try visitor.visitSingularUInt32Field(value: _storage._audioChannelCount, fieldNumber: 13)
      }
      try { if let v = _storage._transport {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.Video, rhs: Analytics_TriggerMediaInformation.Video) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._visualMedia != rhs_storage._visualMedia {return false}
        if _storage._playbackBehavior != rhs_storage._playbackBehavior {return false}
        if _storage._completionTarget != rhs_storage._completionTarget {return false}
        if _storage._softLoopEnabled != rhs_storage._softLoopEnabled {return false}
        if _storage._softLoopDuration != rhs_storage._softLoopDuration {return false}
        if _storage._frameRate != rhs_storage._frameRate {return false}
        if _storage._audioChannelCount != rhs_storage._audioChannelCount {return false}
        if _storage._transport != rhs_storage._transport {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.Video.PlaybackBehavior: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PLAYBACK_BEHAVIOR_STOP"),
    1: .same(proto: "PLAYBACK_BEHAVIOR_LOOP"),
    2: .same(proto: "PLAYBACK_BEHAVIOR_LOOP_FOR_PLAY_COUNT"),
    3: .same(proto: "PLAYBACK_BEHAVIOR_LOOP_FOR_TIME"),
  ]
}

extension Analytics_TriggerMediaInformation.Audio: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.protoMessageName + ".Audio"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "behavior"),
    2: .standard(proto: "playback_behavior"),
    3: .same(proto: "transition"),
    4: .standard(proto: "audio_channel_count"),
    5: .same(proto: "transport"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.behavior) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.playbackBehavior) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._transition) }()
      case 4: try { try decoder.decodeSingularUInt32Field(value: &self.audioChannelCount) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._transport) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.behavior != .tune {
      try visitor.visitSingularEnumField(value: self.behavior, fieldNumber: 1)
    }
    if self.playbackBehavior != .stop {
      try visitor.visitSingularEnumField(value: self.playbackBehavior, fieldNumber: 2)
    }
    try { if let v = self._transition {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if self.audioChannelCount != 0 {
      try visitor.visitSingularUInt32Field(value: self.audioChannelCount, fieldNumber: 4)
    }
    try { if let v = self._transport {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.Audio, rhs: Analytics_TriggerMediaInformation.Audio) -> Bool {
    if lhs.behavior != rhs.behavior {return false}
    if lhs.playbackBehavior != rhs.playbackBehavior {return false}
    if lhs._transition != rhs._transition {return false}
    if lhs.audioChannelCount != rhs.audioChannelCount {return false}
    if lhs._transport != rhs._transport {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.Audio.Behavior: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "BEHAVIOR_TUNE"),
    1: .same(proto: "BEHAVIOR_SOUND"),
  ]
}

extension Analytics_TriggerMediaInformation.Audio.PlaybackBehavior: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PLAYBACK_BEHAVIOR_STOP"),
    1: .same(proto: "PLAYBACK_BEHAVIOR_LOOP"),
    2: .same(proto: "PLAYBACK_BEHAVIOR_NEXT"),
  ]
}

extension Analytics_TriggerMediaInformation.Image: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.protoMessageName + ".Image"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "visual_media"),
    2: .same(proto: "transition"),
    3: .standard(proto: "completion_target"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._visualMedia) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._transition) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.completionTarget) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._visualMedia {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._transition {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.completionTarget != .none {
      try visitor.visitSingularEnumField(value: self.completionTarget, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.Image, rhs: Analytics_TriggerMediaInformation.Image) -> Bool {
    if lhs._visualMedia != rhs._visualMedia {return false}
    if lhs._transition != rhs._transition {return false}
    if lhs.completionTarget != rhs.completionTarget {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Analytics_TriggerMediaInformation.LiveVideo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Analytics_TriggerMediaInformation.protoMessageName + ".LiveVideo"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "visual_media"),
    2: .standard(proto: "frame_rate"),
    3: .standard(proto: "audio_channel_count"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._visualMedia) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.frameRate) }()
      case 3: try { try decoder.decodeSingularUInt32Field(value: &self.audioChannelCount) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._visualMedia {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.frameRate.bitPattern != 0 {
      try visitor.visitSingularDoubleField(value: self.frameRate, fieldNumber: 2)
    }
    if self.audioChannelCount != 0 {
      try visitor.visitSingularUInt32Field(value: self.audioChannelCount, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Analytics_TriggerMediaInformation.LiveVideo, rhs: Analytics_TriggerMediaInformation.LiveVideo) -> Bool {
    if lhs._visualMedia != rhs._visualMedia {return false}
    if lhs.frameRate != rhs.frameRate {return false}
    if lhs.audioChannelCount != rhs.audioChannelCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
